The foreach action in Spark is designed like a forced
 map (so the "map" action occurs on the executors).
 Foreach is useful for a couple of operations in Spark.
 They are required to be used when you want to guarantee an accumulator's value to be correct.
 In addition, they can be used when you want to move data to an external system,
 like a database, though typically a foreachPartition is used for that operation.

 To add to Joe's response, one more thing to note here is that
 foreach() action doesn't return anything.
  So if you want to invoke any transformations on your RDDs on executors without
  returning anything back to driver, you can invoke them
  using foreach() action which is not normally possible with other actions apart from saveAsxxx() actions.

  foreach is an action in spark. It basically takes each element of the RDD and applies a function to that element.

  foreach is performed on the executor nodes or worker nodes.
  It does not get applied on the driver node.
https://community.cloudera.com/t5/Support-Questions/In-spark-why-foreach-is-designed-as-an-action/td-p/120916
https://stackoverflow.com/questions/62043315/apache-spark-take-action-on-executors-in-fully-distributed-mode


Save as text file - does not send data to driver program like collect instead it will save
data on the nodes. That is, saveAsTextFile is distributed.
https://stackoverflow.com/questions/29600293/spark-save-files-distributedly

https://www.waitingforcode.com/apache-spark/apache-spark-data-bigger-than-memory/read

https://www.waitingforcode.com/apache-spark-sql/dataframe-file-bigger-available-memory/read

https://blog.knoldus.com/startdeploy-apache-spark-application-programmatically-using-spark-launcher/
-- submitting spark job programatically

https://towardsdatascience.com/the-art-of-joining-in-spark-dcbd33d693c

https://docs.databricks.com/data/data-sources/sql-databases.html
https://docs.databricks.com/data/data-sources/sql-databases.html#jdbc-parallelism

https://opensource.com/article/19/3/apache-spark-and-dataframes-tutorial
-- This needs to be checked.

https://apacheignite-fs.readme.io/docs/ignite-data-frame
-- Ignite DataFrame Spark DataFrames support by Ignite

https://www.youtube.com/watch?v=MygFqen8VsM
https://medium.com/analytics-vidhya/spark-hierarchy-953c1eb56a81

-- How to Connect Spark to Your Own Datasource
Extending Spark SQL 2 4 with New Data Sources Live Coding Session -Jacek Laskowski - Part - 1
https://www.youtube.com/watch?v=YKkgVEgn2JE
Extending Spark SQL 2 4 with New Data Sources Live Coding Session -Jacek Laskowski - Part - 1
https://www.youtube.com/watch?v=vfd83ELlMfc


http://shzhangji.com/blog/2018/12/08/spark-datasource-api-v2/

https://databricks.com/session/how-to-connect-spark-to-your-own-datasource

https://docs.databricks.com/_static/notebooks/complex-nested-structured.html

https://learnsql.com/blog/sql-window-functions-examples/
https://www.mysqltutorial.org/mysql-window-functions/

https://mungingdata.com/apache-spark/aggregations/
https://sparkbyexamples.com/spark/using-groupby-on-dataframe/

Full outer join

Partitioning in spark
https://www.dezyre.com/article/how-data-partitioning-in-spark-helps-achieve-more-parallelism/297
https://luminousmen.com/post/spark-partitions
https://luminousmen.com/

https://www.youtube.com/watch?v=LDdA1RW_6xo
- Wide vs Narrow Dependencies.
This video also explains how RDDs are in memory and DAG / lineage graph


https://deepsense.ai/optimize-spark-with-distribute-by-and-cluster-by/

https://github.com/deepsense-ai/Seahorse

Need to add in notes - which transformation preserve partitioning and what is the reason
https://www.youtube.com/watch?v=AK1khvHMUvE


https://blog.cloudera.com/how-to-tune-your-apache-spark-jobs-part-1/
https://blog.cloudera.com/how-to-tune-your-apache-spark-jobs-part-2/

https://github.com/JerryLead/SparkInternals/blob/master/markdown/english/5-Architecture.md

https://intellipaat.com/community/6632/what-are-workers-executors-cores-in-spark-standalone-cluster

https://blog.knoldus.com/understanding-the-working-of-spark-driver-and-executor/
https://stackoverflow.com/questions/48800434/spark-executors-are-they-java-processes/48824319
https://stackoverflow.com/questions/32621990/what-are-workers-executors-cores-in-spark-standalone-cluster
- Spark Executors - Are they java processes?
- Yes they are separate JVm - refer ExecutorRunner.scala and Worker.scala

https://freecontent.manning.com/running-spark-an-overview-of-sparks-runtime-architecture/

https://www.edureka.co/blog/interview-questions/top-apache-spark-interview-questions-2016/

https://github.com/Stratio/sparta

https://acadgild.com/blog/spark-use-case-olympics-data-analysis

https://www.lynda.com/Apache-Spark-tutorials/Problem-statement/578078/638995-4.html

https://www.rvsimsr.ac.in/pdf/BA-projects-Ver-0-1.pdf

http://discuss.itversity.com/t/spark-problem-statement/17550